<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="labelDescripcionTokenization.Text" xml:space="preserve">
    <value>   La Tokenización es el proceso de dividir un flujo de texto en palabras, frases, símbolos u otros elementos significativos llamados tokens. 
La lista de tokens se realiza para las tareas tales como el análisis o la minería de texto. La Tokenización es útil tanto en la lingüística (donde es una forma de 
segmentación de texto) y en ciencias de la computación, donde forma parte del análisis léxico. Típicamente, la tokenización se produce a nivel de palabra. 
Sin embargo, a veces es difícil de definir qué se entiende por una "palabra".

   A menudo, un tokenizador se basa en una heurística simple, por ejemplo:

1) Todas las cadenas contiguas de caracteres alfabéticos son parte de un token, del mismo modo con los números.
2) Los tokens están separados por espacios en blanco, como un espacio o un salto de línea, o caracteres de puntuación.
3) La puntuación y espacios en blanco pueden o no estar incluidos en la lista resultante de tokens.

   En lenguajes que usan espacios entre palabras (como la mayoría que utilizan el alfabeto latino, y la mayoría de los lenguajes de programación), este método es 
bastante sencillo. Sin embargo, hay muchos casos tales como contracciones, palabras separadas por guiones, emoticones, y construcciones, como URI (que para 
algunos fines puede contar como tokens individuales). Un ejemplo clásico es "New York-based", que un tokenizador ingenuo podría romperse en el espacio a 
pesar de que el mejor break es (posiblemente) en el guión. 
La tokenizacion es particularmente difícil para los idiomas escritos en Scriptio continua, que exhiben y no hay límites de las palabras, como el griego antiguo, 
chino o tailandés. Algunas formas de abordar los problemas más difíciles incluyen el desarrollo de heurísticas más complejas en donde se consulta una tabla de 
casos especiales comunes, o encajando las fichas a un modelo de lenguaje que identifica las colocaciones en una etapa de procesamiento posterior.

   En esta aplicación se utilizó un codigo extraido de la web desde esta dirección
"http://www.codeproject.com/Articles/12098/Term-frequency-Inverse-document-frequency-implemen", éste codigo implementa la frecuencia de 
término - frecuencia inversa de un documento (TF-IDF), o sea, la frecuencia de ocurrencia del término en la colección de documentos y como sub-proceso
contiene un módulo destinado a la Tokenización de los datos expuestos al proceso principal, en este caso los tweets. En este proceso se determina la
forma de crear los tokens a travez de una expresión regular, esta aplicación consta con una expresión regular incorporada por defecto pero también tiene la 
posibilidad de que el usuario ingrese una expresión propia que le permita manipular la información de una forma especifica conveniente al conjunto de datos
aportado.
</value>
  </data>
</root>